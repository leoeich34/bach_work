# src/ui/main.py

"""
–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ø–∞–Ω–µ–ª—å Streamlit –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞:
‚Ä¢ Batch-–∞–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
‚Ä¢ Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑ Kafka topic=flows
‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π (–ø–æ—Ä—Ç-—Å–∫–∞–Ω, DoS, tcpreplay)
"""

from __future__ import annotations
import json
import subprocess
import threading
import time
from collections import deque
from pathlib import Path
from typing import Tuple

import joblib
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from kafka import KafkaConsumer

from src.actions.firewall import block_ip
from src.ui.utils import load_model_and_scaler, prepare_dataframe, predict_batch

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
MODEL_PATH = Path("src/models/saved/random_forest.joblib")
SCALER_PATH = Path("src/features/scaler.joblib")
COLUMNS_FILE = Path("src/features/columns.txt")
THRESHOLD = 0.80

KAFKA_BROKER = "localhost:29092"
KAFKA_TOPIC = "flows"
LIVE_INTERVAL = 5  # —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
LIVE_WINDOW = 12   # —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–æ—á–µ–∫ —Ö—Ä–∞–Ω–∏—Ç—å

st.set_page_config(
    page_title="Anomaly-Detector UI",
    page_icon="üö¶",
    layout="wide",
    initial_sidebar_state="expanded",
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
@st.cache_resource
def init_assets() -> Tuple[object, object]:
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    return model, scaler

model, scaler = init_assets()

# –¢–∞–±—ã
tab_batch, tab_live, tab_sim = st.tabs([
    "üîç Batch-–∞–Ω–∞–ª–∏–∑",
    "üìà Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
    "üö® –°–∏–º—É–ª—è—Ü–∏—è",
])

# ---------------------- TAB: Batch-–∞–Ω–∞–ª–∏–∑ ----------------------
with tab_batch:
    st.header("üîç Batch-–∞–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
    uploaded = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV / Parquet / NPY —Å —Ñ–∏—á–∞–º–∏ (70 —Å—Ç–æ–ª–±—Ü–æ–≤)",
        type=["csv", "parquet", "npy"],
        key="batch_uploader"
    )
    if not uploaded:
        st.info("‚¨ÖÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
    else:
        # –ß—Ç–µ–Ω–∏–µ
        if uploaded.name.endswith(".csv"):
            df_raw = pd.read_csv(uploaded, low_memory=False)
        elif uploaded.name.endswith(".parquet"):
            df_raw = pd.read_parquet(uploaded)
        else:  # npy
            arr = np.load(uploaded)
            # –¥–ª—è npy —Ç—Ä–µ–±—É–µ—Ç—Å—è columns.txt
            cols = [c.strip() for c in COLUMNS_FILE.read_text().splitlines() if c.strip()]
            df_raw = pd.DataFrame(arr, columns=cols)

        df = prepare_dataframe(df_raw, COLUMNS_FILE)
        X = df.values
        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} —Å—Ç—Ä–æ–∫, {df.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")

        # Batch-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        preds, probs = predict_batch(model, scaler, X, THRESHOLD)

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–µ–∞–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º
        st.subheader("‚ö° –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–µ–∞–ª—å–Ω—ã–º –º–µ—Ç–∫–∞–º (Label)")
        if "Label" in df_raw.columns:
            vc = df_raw["Label"].value_counts()
            fig = px.pie(
                names=vc.index.tolist(),
                values=vc.values.tolist(),
                color_discrete_sequence=px.colors.qualitative.Set2,
                title="–†–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏"
            )
        else:
            count_anom = int((preds == 1).sum())
            fig = px.pie(
                names=["Benign", "Anomaly"],
                values=[len(df)-count_anom, count_anom],
                color_discrete_sequence=px.colors.qualitative.Set2,
                title="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏"
            )
        st.plotly_chart(fig, use_container_width=True)

        # –¢–æ–ø-–∞–Ω–∏–º–∞–ª–∏–π –ø–æ score
        st.subheader("üîé –¢–æ–ø-–∞–Ω–∏–º–∞–ª–∏–π –ø–æ score")
        top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø N:", 5, 100, 20)
        idx = np.argsort(-probs)[:top_n]
        df_top = df_raw.iloc[idx].copy()
        df_top.insert(0, "score", probs[idx])
        st.dataframe(df_top, use_container_width=True)

        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
        buf = df_raw.copy()
        buf["score"] = probs
        buf["label_pred"] = preds
        st.download_button(
            "üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
            data=buf.to_csv(index=False),
            file_name="predictions.csv",
            mime="text/csv"
        )

# ---------------------- TAB: Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ ----------------------
with tab_live:
    st.header("üìà Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç—Ä–∞—Ñ–∏–∫–∞")
    st.write(f"–ß–∏—Ç–∞–µ–º –∏–∑ Kafka `topic={KAFKA_TOPIC}` –∫–∞–∂–¥—ã–µ {LIVE_INTERVAL}s.")

    # –ò—Å—Ç–æ—Ä–∏—è
    times = deque(maxlen=LIVE_WINDOW)
    counts = deque(maxlen=LIVE_WINDOW)

    placeholder_metric = st.empty()
    placeholder_chart = st.empty()

    def consume_live():
        consumer = KafkaConsumer(
            KAFKA_TOPIC,
            bootstrap_servers=KAFKA_BROKER,
            value_deserializer=lambda b: json.loads(b.decode()),
            auto_offset_reset="latest",
            enable_auto_commit=True
        )
        for msg in consumer:
            batch = np.array(msg.value, dtype=float)
            Xb = scaler.transform(batch)
            probs_b = model.predict_proba(Xb)[:,1]
            num = int((probs_b >= THRESHOLD).sum())

            t = time.strftime("%H:%M:%S")
            times.append(t)
            counts.append(num)

            placeholder_metric.metric("–ê–Ω–æ–º–∞–ª–∏–π –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º –±–∞—Ç—á–µ", f"{num}")
            fig = go.Figure(go.Scatter(x=list(times), y=list(counts), mode="lines+markers"))
            fig.update_layout(
                title="–ê–Ω–æ–º–∞–ª–∏–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏",
                xaxis_title="–í—Ä–µ–º—è", yaxis_title="–ß–∏—Å–ª–æ –∞–Ω–æ–º–∞–ª–∏–π"
            )
            placeholder_chart.plotly_chart(fig, use_container_width=True)

    if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"):
        threading.Thread(target=consume_live, daemon=True).start()
        st.info("Live-–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω.")

    # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ IP (–µ—Å–ª–∏ –µ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏–µ suspects –≤ session_state)
    st.write("---")
    st.subheader("üîí –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö IP")
    if "suspects" not in st.session_state:
        st.session_state.suspects = set()
    for ip in st.session_state.suspects:
        c1, c2 = st.columns([3,1])
        c1.write(f"‚Äì {ip}")
        if c2.button("–ë–ª–æ–∫", key=f"blk_{ip}"):
            block_ip(ip)
            st.success(f"IP {ip} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω")

# ---------------------- TAB: –°–∏–º—É–ª—è—Ü–∏—è ----------------------
with tab_sim:
    st.header("üö® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π")
    target = st.text_input("–¶–µ–ª—å (IP)", "127.0.0.1")
    iface  = st.text_input("–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è tcpreplay", "en0")

    if st.button("üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ—Ä—Ç-—Å–∫–∞–Ω (nmap)"):
        subprocess.Popen(["nmap","-sS","-p1-1000",target])
        st.info("nmap –≤ —Ñ–æ–Ω–µ‚Ä¶")

    if st.button("üí• DoS-–∏–º–ø—É–ª—å—Å (hping3)"):
        subprocess.Popen(["sudo","hping3","-S","-c","2000","-i","u1000","-p","80",target])
        st.info("hping3 –∑–∞–ø—É—â–µ–Ω‚Ä¶")

    if st.button("‚ñ∂Ô∏è tcpreplay sample"):
        sample = Path("samples/test_attack.pcap")
        subprocess.Popen(["sudo","tcpreplay","--intf1",iface,str(sample)])
        st.info("tcpreplay –∑–∞–ø—É—â–µ–Ω‚Ä¶")